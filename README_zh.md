# CogVLM

ğŸ“– [Paperï¼ˆè®ºæ–‡ï¼‰](./assets/cogvlm-paper.pdf)

ğŸŒ [web demoï¼ˆæµ‹è¯•ç½‘å€ï¼‰](http://36.103.203.44:7861/)

ğŸ”¥ **News**: CogVLM bilingual version is available [online](https://chatglm.cn/)! Welcome to try it out!

ğŸ”¥ **News**: CogVLMä¸­è‹±åŒè¯­ç‰ˆæ­£å¼[ä¸Šçº¿](https://chatglm.cn/)äº†ï¼æ¬¢è¿ä½“éªŒï¼

ğŸ”¥ **News**: CogVLMçš„huggingfaceç‰ˆå·²å¼€æºï¼åŒ…æ‹¬[**cogvlm-chat**](https://huggingface.co/THUDM/cogvlm-chat-hf), **[cogvlm-grounding-generalist](https://huggingface.co/THUDM/cogvlm-grounding-generalist-hf)/[base](https://huggingface.co/THUDM/cogvlm-grounding-base-hf)**, **[cogvlm-base-490](https://huggingface.co/THUDM/cogvlm-base-490-hf)/[224](https://huggingface.co/THUDM/cogvlm-base-224-hf)**. ä»…ä½¿ç”¨å‡ è¡Œä»£ç å³å¯è¿›è¡Œæ¨ç†ï¼Œå…·ä½“ä½¿ç”¨æ–¹æ³•è¯·å‚è€ƒ[è¿™é‡Œ](#-transformers)ã€‚

[README in English](./README.md)

## ç®€ä»‹
- CogVLM æ˜¯ä¸€ä¸ªå¼ºå¤§çš„å¼€æºè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰ã€‚CogVLM-17B æ‹¥æœ‰ 100 äº¿è§†è§‰å‚æ•°å’Œ 70 äº¿è¯­è¨€å‚æ•°ã€‚

- CogVLM-17B åœ¨ 10 ä¸ªç»å…¸è·¨æ¨¡æ€åŸºå‡†æµ‹è¯•ä¸Šå–å¾—äº† SOTA æ€§èƒ½ï¼ŒåŒ…æ‹¬ NoCapsã€Flicker30k captioningã€RefCOCOã€RefCOCO+ã€RefCOCOgã€Visual7Wã€GQAã€ScienceQAã€VizWiz VQA å’Œ TDIUCï¼Œè€Œåœ¨ VQAv2ã€OKVQAã€TextVQAã€COCO captioning ç­‰æ–¹é¢åˆ™æ’åç¬¬äºŒï¼Œè¶…è¶Šæˆ–ä¸ PaLI-X 55B æŒå¹³ã€‚æ‚¨å¯ä»¥é€šè¿‡çº¿ä¸Š [demo](http://36.103.203.44:7861) ä½“éªŒ CogVLM å¤šæ¨¡æ€å¯¹è¯ã€‚

<div align="center">
    <img src=assets/metrics-min.png width=80% />
</div>

## ç¤ºä¾‹

<!-- CogVLM is powerful for answering various types of visual questions, including **Detailed Description & Visual Question Answering**,  **Complex Counting**, **Visual Math Problem Solving**, **OCR-Free Reasonging**, **OCR-Free Visual Question Answering**, **World Knowledge**, **Referring Expression Comprehension**, **Programming with Visual Input**, **Grounding with Caption**, **Grounding Visual Question Answering**, etc. -->
* CogVLM èƒ½å¤Ÿå‡†ç¡®åœ°æè¿°å›¾åƒï¼Œ**å‡ ä¹ä¸ä¼šå‡ºç°å¹»è§‰**ã€‚
    <details>
    <summary>ç‚¹å‡»æŸ¥çœ‹ä¸ LLAVA-1.5 å’Œ MiniGPT-4 çš„æ¯”è¾ƒã€‚</summary>

    ![LLAVA Comparision](assets/llava-comparison-min.png)
    </details>
    <br>

* CogVLM èƒ½ç†è§£å’Œå›ç­”å„ç§ç±»å‹çš„é—®é¢˜ï¼Œå¹¶æœ‰ä¸€ä¸ª**è§†è§‰å®šä½**ç‰ˆæœ¬ã€‚
<div align="center">
    <img src=assets/pear_grounding.png width=90% />
</div>

<br>

* CogVLM æœ‰æ—¶æ¯” GPT-4V(ision) æå–åˆ°æ›´å¤šçš„ç»†èŠ‚ä¿¡æ¯ã€‚
<div align="center">
    <img src=assets/compare-min.png width=90% />
</div>

<!-- ![compare](assets/compare.png) -->
<br> 

<details>
<summary>ç‚¹å‡»å±•å¼€æ›´å¤šç¤ºä¾‹ã€‚</summary>

![Chat Examples](assets/chat.png)

</details>

## æ–¹æ³•
CogVLM æ¨¡å‹åŒ…æ‹¬å››ä¸ªåŸºæœ¬ç»„ä»¶ï¼šè§†è§‰å˜æ¢å™¨ï¼ˆViTï¼‰ç¼–ç å™¨ã€MLPé€‚é…å™¨ã€é¢„è®­ç»ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆGPTï¼‰å’Œä¸€ä¸ª**è§†è§‰ä¸“å®¶æ¨¡å—**ã€‚æ›´å¤šç»†èŠ‚è¯·å‚è§[è®ºæ–‡](./assets/cogvlm-paper.pdf)ã€‚

<div align="center">
    <img src=assets/method-min.png width=70% />
</div>

## å…¥é—¨æŒ‡å—
æˆ‘ä»¬æä¾›ä¸¤ç§å›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆGUIï¼‰è¿›è¡Œæ¨¡å‹æ¨æ–­ï¼Œåˆ†åˆ«æ˜¯**ç½‘é¡µæ¼”ç¤º**å’Œ**å‘½ä»¤è¡Œç•Œé¢ï¼ˆCLIï¼‰**ã€‚å¦‚æœæ‚¨æƒ³åœ¨Pythonä»£ç ä¸­ä½¿ç”¨å®ƒï¼Œå¾ˆå®¹æ˜“ä¿®æ”¹CLIè„šæœ¬ä»¥é€‚åº”æ‚¨çš„æƒ…å†µã€‚

é¦–å…ˆï¼Œéœ€è¦å®‰è£…ä¾èµ–é¡¹ã€‚

```bash
pip install -r requirements.txt
python -m spacy download en_core_web_sm
```

#### ç¡¬ä»¶è¦æ±‚
* æ¨¡å‹æ¨æ–­ï¼š1 * A100(80G) æˆ– 2 * RTX 3090(24G)ã€‚
* å¾®è°ƒï¼š4 * A100(80G) [æ¨è] æˆ– 8 * RTX 3090(24G)ã€‚

<!-- ### Online Web Demo
We provide a [web demo](http://36.103.203.44:7861/) based on [Gradio](https://gradio.app). -->

### ç½‘é¡µæ¼”ç¤º
æˆ‘ä»¬è¿˜æä¾›åŸºäºGradioçš„æœ¬åœ°ç½‘é¡µæ¼”ç¤ºã€‚é¦–å…ˆï¼Œé€šè¿‡è¿è¡Œ pip install gradio å®‰è£…Gradioã€‚ç„¶åä¸‹è½½å¹¶è¿›å…¥æ­¤ä»“åº“ï¼Œè¿è¡Œ web_demo.pyã€‚å…·ä½“ä½¿ç”¨æ–¹å¼å¦‚ä¸‹ï¼š

```bash
python web_demo.py --from_pretrained cogvlm-chat --version chat --english --bf16
python web_demo.py --from_pretrained cogvlm-grounding-generalist --version base --english --bf16
```
ç½‘é¡µæ¼”ç¤ºçš„ GUI ç•Œé¢å¦‚ä¸‹ï¼š
<div align="center">
    <img src=assets/web_demo-min.png width=70% />
</div>

### CLI
æˆ‘ä»¬å¼€æºäº†ä¸åŒä¸‹æ¸¸ä»»åŠ¡çš„æ¨¡å‹æƒé‡ï¼š

* cogvlm-chat ç”¨äºå¯¹é½çš„æ¨¡å‹ï¼Œåœ¨æ­¤ä¹‹åæ”¯æŒåƒ GPT-4V ä¸€æ ·çš„èŠå¤©ã€‚
* cogvlm-base-224 æ–‡æœ¬-å›¾åƒé¢„è®­ç»ƒåçš„åŸå§‹æƒé‡ã€‚
* cogvlm-base-490 ä» cogvlm-base-224 å¾®è°ƒå¾—åˆ°çš„ 490px åˆ†è¾¨ç‡ç‰ˆæœ¬ã€‚
* cogvlm-grounding-generalist è¿™ä¸ªæƒé‡æ”¯æŒä¸åŒçš„è§†è§‰å®šä½ä»»åŠ¡ï¼Œä¾‹å¦‚ RECã€Grounding Captioning ç­‰ã€‚

é€šè¿‡CLIæ¼”ç¤ºï¼Œæ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼š
```bash
python cli_demo.py --from_pretrained cogvlm-base-224 --version base --english --bf16 --no_prompt
python cli_demo.py --from_pretrained cogvlm-base-490 --version base --english --bf16 --no_prompt
python cli_demo.py --from_pretrained cogvlm-chat --version chat --english --bf16
python cli_demo.py --from_pretrained cogvlm-grounding-generalist --version base --english --bf16
```
è¯¥ç¨‹åºä¼šè‡ªåŠ¨ä¸‹è½½ sat æ¨¡å‹å¹¶åœ¨å‘½ä»¤è¡Œä¸­è¿›è¡Œäº¤äº’ã€‚æ‚¨å¯ä»¥é€šè¿‡è¾“å…¥æŒ‡ä»¤å¹¶æŒ‰ Enter ç”Ÿæˆå›å¤ã€‚
è¾“å…¥ clear å¯æ¸…é™¤å¯¹è¯å†å²ï¼Œè¾“å…¥ stop å¯åœæ­¢ç¨‹åºã€‚

### ğŸ¤— Transformers

ä½¿ç”¨Transformerså¯¹CogVLMè¿›è¡Œæ¨ç†ï¼Œåªéœ€è¦å¦‚ä¸‹å‡ è¡Œä»£ç ï¼š

```python
import torch
import requests
from PIL import Image
from transformers import AutoModelForCausalLM, LlamaTokenizer

tokenizer = LlamaTokenizer.from_pretrained('lmsys/vicuna-7b-v1.5')
model = AutoModelForCausalLM.from_pretrained(
    'THUDM/cogvlm-chat-hf',
    torch_dtype=torch.bfloat16,
    low_cpu_mem_usage=True,
    trust_remote_code=True
).to('cuda').eval()

query = 'Describe this image'
image = Image.open(requests.get('https://github.com/THUDM/CogVLM/blob/main/examples/1.png?raw=true', stream=True).raw).convert('RGB')
inputs = model.build_conversation_input_ids(tokenizer, query=query, history=[], images=[image])
inputs = {
    'input_ids': inputs['input_ids'].unsqueeze(0).to('cuda'),
    'token_type_ids': inputs['token_type_ids'].unsqueeze(0).to('cuda'),
    'attention_mask': inputs['attention_mask'].unsqueeze(0).to('cuda'),
    'images': [[inputs['images'][0].to('cuda').to(torch.bfloat16)]],
}
gen_kwargs = {"max_length": 2048, "do_sample": False}

with torch.no_grad():
    outputs = model.generate(**inputs, **gen_kwargs)
    outputs = outputs[:, inputs['input_ids'].shape[1]:]
    print(tokenizer.decode(outputs[0]))

# Two professional basketball players are playing against each other. On the left side, there is Kobe Bryant wearing a yellow jersey with the number 24 on it. He is holding a brown basketball. On the right side, there is another player wearing a blue and red jersey, blocking Kobe's movement. Behind them, there are many spectators watching the game.</s>
```

## è®¸å¯

æ­¤å­˜å‚¨åº“ä¸­çš„ä»£ç æ˜¯æ ¹æ® [Apache-2.0 è®¸å¯](./LICENSE) å¼€æ”¾æºç ï¼Œè€Œä½¿ç”¨ CogVLM æ¨¡å‹æƒé‡å¿…é¡»éµå¾ª [æ¨¡å‹è®¸å¯](./MODEL_LICENSE)ã€‚

## å¼•ç”¨ & é¸£è°¢

å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„å·¥ä½œæœ‰å¸®åŠ©ï¼Œè¯·è€ƒè™‘å¼•ç”¨ä»¥ä¸‹è®ºæ–‡ï¼š
```

```
åœ¨ CogVLM çš„æŒ‡ä»¤å¾®è°ƒé˜¶æ®µï¼Œæˆ‘ä»¬ä½¿ç”¨äº†æ¥è‡ª [MiniGPT-4](https://github.com/Vision-CAIR/MiniGPT-4) ã€ [LLAVA](https://github.com/haotian-liu/LLaVA) ã€ [LRV-Instruction](https://github.com/FuxiaoLiu/LRV-Instruction)ã€ [LLaVAR](https://github.com/SALT-NLP/LLaVAR) å’Œ [Shikra](https://github.com/shikras/shikra) é¡¹ç›®çš„ä¸€äº›è‹±æ–‡å›¾åƒ-æ–‡æœ¬æ•°æ®ï¼Œä»¥åŠè®¸å¤šç»å…¸çš„è·¨æ¨¡æ€å·¥ä½œæ•°æ®é›†ã€‚æˆ‘ä»¬è¡·å¿ƒæ„Ÿè°¢ä»–ä»¬çš„è´¡çŒ®ã€‚
